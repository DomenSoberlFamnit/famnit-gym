import gymnasium as gym
import famnit_gym
import numpy as np
from queue import PriorityQueue

# Actions in their order 0 - 3.
actions = [(0, -1), (1, 0), (0, 1), (-1, 0)]

# Create a custom map as a numpy array.
map = np.array(
    [
        [0,0,0,0,0,0,1,0,0,0],
        [2,0,1,1,1,3,1,0,0,0],
        [0,0,0,0,1,1,1,1,0,1],
        [0,1,2,0,1,0,0,0,0,0],
        [0,1,0,0,1,0,0,0,2,0],
        [0,0,0,0,0,0,0,2,0,0],
        [1,1,1,1,1,1,1,0,0,1],
        [0,0,2,0,0,0,0,0,0,0],
        [0,5,0,0,2,0,2,0,2,0],
        [0,0,0,0,0,0,0,0,0,0],
    ]
)

initial_state = (1, 8)  # Initial state is the tile with value 5.
goal_state = (5, 1)  # Goal state is the tile with value 3.

# Get the list of all legal state transitions (action, successor).
def state_transitions(state):
    (x, y) = state
    (height, width) = map.shape
    successors = []

    # Try all possible actions.
    for (action, (dx, dy)) in enumerate(actions):
        x1 = x + dx
        y1 = y + dy

        # Check if the destination tile is empty.
        if x1 >= 0 and x1 < width and y1 >= 0 and y1 < height:
            # If empty, the action is legal.
            if map[y1][x1] == 0 or map[y1][x1] == 3:
                successors.append((action, (x1, y1)))

    return successors

# The Manhattan distance to the goal state.
def heuristic(state):    
    (x0, y0) = state
    (x1, y1) = goal_state
    return abs(x1 - x0) + abs(y1 - y0)

### Execute the A* algorithm to find the path from the initial to the goal state. ###

g_scores = {}  # Store the best g-scores for all genertaed nodes.
transitions = {}  # Store all (parent, action) transitions to recunstruct the final path.
priority = PriorityQueue()  # Priority queue based on the f-score.

# Store the initial state into all three data structures.
g_scores[initial_state] = 0
transitions[initial_state] = (None, None)  # No parent, no action to get there.
priority.put((heuristic(initial_state), initial_state)) # f(x) = 0 + f(x)

# Until either a solution is found or priority queue empties.
solution = None
while solution is None and not priority.empty():
    (_, state) = priority.get()  # Get a state with the lowest f-score.

    # If this is the goal state, we found a solution.
    if state == goal_state:
        solution = state

    # Otherwise, expand the node.
    else:
        # Generate all it's successors.
        for (action, successor) in state_transitions(state):
            # If that successor has not yet been generated, add it to the data structures.
            if successor not in g_scores:
                g_scores[successor] = g_scores[state] + 1  # One step farther from it's parent.
                transitions[successor] = (state, action)  # Generated by this action from it's parent.
                priority.put((g_scores[successor] + heuristic(successor), successor)) # f(x) = g(x) + h(x)
            
            # Otherwise, check if the new path is better than the existing one.
            else:
                g_previous = g_scores[successor]  # The previous g-score.
                g_score = g_scores[state] + 1  # The new g-score.
                if g_score < g_previous:  # If the new one is better.
                    g_scores[successor] = g_score  # Store the new g-score.
                    transitions[successor] = (state, action)  # It now has a different parent.
                    priority.put((g_score + heuristic(successor), successor))  # f(x) = g(x) + h(x)

# Have we found a solution?
if solution is None:
    print('No solution had been found.')
    quit()

# If yes, reconstruct the path.
plan = []  # A sequence of actions from the initial state.
(parent, action) = transitions[solution]  # Start at the found goal state.

# Until we reach the root node, which has no parent.
while parent is not None:
    plan = [action] + plan  # Add the action that got as to this state.
    (parent, action) = transitions[parent]  # Get the parent.

# Build the Sokoban environment to execute the plan.
env = gym.make('famnit_gym/Sokoban-v1', render_mode='human', options={'map_template': map})
env.reset()

# Execite every action in the plan.
for action in plan:
     _, _, _, truncated, _ = env.step(action)
     
     # Allowe the user to close the window.
     if truncated:
        break
